{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "In some cases, we may not know the number of segments or we may wish to compare a power law against other types of rating models.\n",
    "For these cases, we can use information criteria to select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tutorial data\n",
    "from ratingcurve import data\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%xmode minimal\n",
    "#suppress warnings and errors\n",
    "\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from ratingcurve.ratingmodel import PowerLawRating\n",
    "\n",
    "from ratingcurve import data\n",
    "\n",
    "df = data.load('green channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the data to ratings with 1 to 4 segments and determine which is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# OUtput supressed, this will print \"Finished\" after running each of the four models\n",
    "\n",
    "segments = [1, 2, 3, 4]\n",
    "traces = []\n",
    "for segment in segments:\n",
    "    powerrating = PowerLawRating(q=df['q'],\n",
    "                             h=df['stage'], \n",
    "                             q_sigma=df['q_sigma'],\n",
    "                             segments=segment,\n",
    "                             prior={'distribution':'uniform'})\n",
    "    \n",
    "    trace = powerrating.fit(n=100_000)\n",
    "    traces.append(pm.compute_log_likelihood(trace)) # Add arg to compute log likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now use `arviz.compare` to format the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model will generate warnings about the LOO\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "compare_dict = {f'{i} segment': traces[i-1] for i in segments}\n",
    "az.compare(compare_dict, ic='LOO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, the 2-segment model was ranked highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residuals\n",
    "In practice, it can be helpful to plot to rating error\n",
    "(the deviations between the rating fit and the discharge observations).\n",
    "Here is a demonstration of how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "segments = 2\n",
    "powerrating = PowerLawRating(q=df['q'],\n",
    "                             h=df['stage'], \n",
    "                             q_sigma=df['q_sigma'],\n",
    "                             segments=segments,\n",
    "                             prior={'distribution':'uniform'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with powerrating:\n",
    "    mean_field = pm.fit(method='advi', n=150_000)\n",
    "    trace = mean_field.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(7,7), sharey=True)\n",
    "\n",
    "powerrating.plot(trace, ax[0])\n",
    "powerrating.plot_residuals(trace, ax[1])\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "ax[1].set_ylabel('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
